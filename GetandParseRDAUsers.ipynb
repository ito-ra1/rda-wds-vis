{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16f271e",
   "metadata": {},
   "source": [
    "# Data scraping - RDA\n",
    "\n",
    "Created on Thu 9 September, 21:37:18 2021\n",
    "\n",
    "Alicia Urquidi Diaz, 2021 [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/).\n",
    "\n",
    "Based on code by [Seiya Terada](https://www.linkedin.com/in/seiya-terada-58381817a/) (co-op student at WDS-ITO in Spring 2020) and Alicia Urquidi Diaz.\n",
    "\n",
    "--------\n",
    "This script scrapes membership data from the rd-alliance.org website. We developed this to extract & visualize de-identified RDA membership data by different parameters (region, type of institution, disciplines, etc.).\n",
    "\n",
    "## Import packages and create output files\n",
    "\n",
    "This script uses `requests` to grab HTML from URLs, `BeautifulSoup` to parse the HTML, and regex (`re`) to clean the data into tab-separated rows.\n",
    "\n",
    "The output will be two text files: **Users** and **Groups**. \n",
    "\n",
    "The next cell imports the packages and creates the files in tab-delimited format with headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2159b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "out = open('Users.txt','a+',encoding='utf-8')\n",
    "out.write('user_ID\\tProfessional title\\tPrimary Domain/Field of Expertise (Other)\\tOrganization name\\tOrganization type\\tCountry\\n')\n",
    "gr = open('Groups.txt','a+',encoding='utf-8')\n",
    "gr.write('user_ID\\tGroup\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ccaeb3",
   "metadata": {},
   "source": [
    "## Set counter\n",
    "\n",
    "I use a counter to generate all member page URLs following the `https://www.rd-alliance.org/user/[counter]` schema. As of August 25, 2021, the RDA boasted 12009 registered members. This does not mean that the highest user number is 12009, so this is a bit of trial and error and, as of the same date, the highest user number in the 29550s. \n",
    "\n",
    "I set the counter higher (30000) to be on the safe side.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32bae52",
   "metadata": {},
   "source": [
    "\n",
    "For every number, if `requests` returns `200` the script grabs the HTML, parses through it, and writes a tab-separated record into a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start counter from 1 to 30000\n",
    "c = 30000\n",
    "#ids = 3498034\n",
    "l = []\n",
    "while c > 0:\n",
    "    c = c - 1\n",
    "    #ids = (c * ids)/(c - 3)\n",
    "    if c % 1000 == 0:\n",
    "        print('counter is at '+str(c))\n",
    "    r = requests.get(\"https://www.rd-alliance.org/user/\"+str(c))\n",
    "    if r.status_code != 200:\n",
    "        l.append(c)\n",
    "        continue\n",
    "    else:\n",
    "        w = r.text  \n",
    "        out.write(str(c)+'\\t')\n",
    "        soup = BeautifulSoup(w, 'lxml')\n",
    "        try:\n",
    "            protitle = soup.find('div', class_='field-name-field-profile-professiona-title')\n",
    "        except:\n",
    "            print('Could not find professional title in file '+str(c))\n",
    "        try:\n",
    "            expert = soup.find('div', class_='field-name-field-profile-primary-domain')\n",
    "        except:\n",
    "            print('Could not find primary field of work in file '+str(c))\n",
    "        try:\n",
    "            organization = soup.find('div', class_='field-name-field-profile-organization-name')\n",
    "        except:\n",
    "            print('Could not find organization in file '+str(c))\n",
    "        try:\n",
    "            o_type = soup.find('div', class_='field-name-field-profile-organization-type')\n",
    "        except:\n",
    "            print('Could not find org type in file '+str(c))\n",
    "        try:\n",
    "            country = soup.find('div', class_='field-name-field-profile-country')\n",
    "        except:\n",
    "            print('Could not find country in file '+str(c))\n",
    "        try:\n",
    "            groups = soup.find('div',class_='view-mygroups')\n",
    "        except:\n",
    "            print('Could not find groups in file '+str(c))\n",
    "        try:\n",
    "            p = re.sub(r'Professional title:', r'', protitle.text)\n",
    "            out.write(p+'\\t')\n",
    "        except:\n",
    "            out.write('NULL\\t')\n",
    "            print('Could not write professional title for '+str(c))\n",
    "        try:\n",
    "            e = re.sub(r'Primary Domain\\/Field of Expertise \\(Other\\):', r'', expert.text)\n",
    "            out.write(e+'\\t')\n",
    "        except:\n",
    "            out.write('NULL\\t')\n",
    "            print('Could not write primary field of work for '+str(c))\n",
    "        try:\n",
    "            ot = re.sub(r'Organization name:', r'', organization.text)\n",
    "            out.write(ot+'\\t')\n",
    "        except:\n",
    "            out.write('NULL\\t')\n",
    "            print('Could not write org name for '+str(c))\n",
    "        try:\n",
    "            ty = re.sub(r'Organization type:', r'', o_type.text)\n",
    "            out.write(ty+'\\t')\n",
    "        except:\n",
    "            out.write('NULL\\t')\n",
    "            print('Could not write org type for '+str(c))\n",
    "        try:\n",
    "            co = re.sub(r'Country:', r'', country.text)\n",
    "            out.write(co+'\\n')\n",
    "        except:\n",
    "            out.write('NULL\\n')\n",
    "            print('Could not write country name for '+str(c))\n",
    "        try:\n",
    "            for groups in soup.find_all('div', class_='view-mygroups'):\n",
    "                for a in groups.find_all('a', href=re.compile('^/groups/')):\n",
    "                    gr.write(str(c)+'\\t'+a.text+'\\n') #for getting text between the link\n",
    "        except:\n",
    "            continue\n",
    "out.close()\n",
    "gr.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
